{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT_VERBS = ['tratar', 'estabelecer', 'marcar', 'vir', 'colocar',\\\n",
    "           'fechar', 'dar', 'cair', 'encontrar', 'registrar',\\\n",
    "           'levar', 'receber', 'apresentar', 'passar', 'deixar',\\\n",
    "           'chegar', 'ficar', 'fazer', 'ter', 'ser']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(startpath):\n",
    "    selected_files = []\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        level = root\n",
    "        for f in files:\n",
    "            if 'dls/verb' in level and '.xml' in f and 'ontology' not in f:\n",
    "                selected_files.append(level + '/' + f)\n",
    "    return selected_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_files = list_files(Path.cwd() / 'data/CSTNews 6.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_file = {}\n",
    "id_synstes = []\n",
    "with open(Path.cwd() / 'data/wordnet/index.sense') as f:\n",
    "    for ix, line in enumerate(f.read().split('\\n')):\n",
    "        if len(line) > 1:\n",
    "            verbs_file[line.split()[0]] = line.split()[1]\n",
    "            id_synstes.append(line.split()[1])\n",
    "f.close()\n",
    "id_synstes = list(set(id_synstes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_sentences = []\n",
    "stem_sentences = []\n",
    "output_sentences = []\n",
    "output_selected_verb_sentences = []\n",
    "selected_arrays = []\n",
    "total_anns = 0\n",
    "s = []\n",
    "for name_file in selected_files:\n",
    "    with open(name_file, 'r') as f:\n",
    "        xml = f.read().lower()\n",
    "        texts = re.findall(r'<texto(.*?)</texto>', xml, re.DOTALL)\n",
    "        \n",
    "        for text in texts:\n",
    "            sentences = re.findall(r'<p>(.*?)</p>', text, re.DOTALL)\n",
    "            for sentence in sentences:\n",
    "                tokens = re.findall(r'<token>(.*?)</token>', text, re.DOTALL)\n",
    "                temp_in = []\n",
    "                temp_out = []\n",
    "                temp_stem = []\n",
    "                temp_sel = []\n",
    "                temp = []\n",
    "                for token in tokens:\n",
    "                    word_value = re.findall(r'<valor>(.*?)</valor>', token, re.DOTALL)\n",
    "                    sense_value = re.findall(r'<synset selecionado=\"true\">(.*?)</synset>', token, re.DOTALL)\n",
    "                    stem_value = re.findall(r'<lema>(.*?)</lema>', token, re.DOTALL)\n",
    "                    \n",
    "                    \n",
    "                    temp_stem.append(stem_value[0])\n",
    "                    if len(sense_value) > 0:\n",
    "                        temp.append(word_value[0] + '<' + (8 - len(sense_value[0])) * '0' + sense_value[0] + '>')\n",
    "                        if stem_value[0] in PT_VERBS:\n",
    "                            temp_in.append(stem_value[0] + '_tag')\n",
    "                            temp_sel.append((8 - len(sense_value[0])) * '0' + sense_value[0])\n",
    "                            s.append((8 - len(sense_value[0])) * '0' + sense_value[0])\n",
    "                        else:\n",
    "                            temp_in.append(word_value[0])\n",
    "                            temp_sel.append(word_value[0])\n",
    "                        temp_out.append((8 - len(sense_value[0])) * '0' + sense_value[0])\n",
    "                    else:\n",
    "                        temp.append(word_value[0])\n",
    "                        temp_in.append(word_value[0])\n",
    "                        temp_sel.append(word_value[0])\n",
    "                        temp_out.append(word_value[0])\n",
    "                        \n",
    "                selected_arrays.append(' '.join(temp))\n",
    "                input_sentences.append(' '.join(temp_in))\n",
    "                output_sentences.append(' '.join(temp_out))\n",
    "                stem_sentences.append(' '.join(temp_stem))\n",
    "                output_selected_verb_sentences.append(' '.join(temp_sel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(zip(input_sentences, output_sentences, output_selected_verb_sentences))\n",
    "sentences = list(set(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_in_all = open(Path.cwd() / 'data/disambiguation/test/all_verbs_lemma_in.txt', 'w')\n",
    "f_out_all = open(Path.cwd() / 'data/disambiguation/test/all_verbs_lemma_out.txt', 'w') \n",
    "f_in_sel = open(Path.cwd() / 'data/disambiguation/test/verbs_selected_lemma_in.txt', 'w')\n",
    "f_out_sel = open(Path.cwd() / 'data/disambiguation/test/verbs_selected_lemma_out.txt', 'w')\n",
    "r = 0\n",
    "for input_s, output_s_all, output_s_sel in sentences:\n",
    "    #print(input_s)\n",
    "    input_s = ' '.join(input_s.split()[1:])\n",
    "    output_s_all = ' '.join(output_s_all.split()[1:])\n",
    "    output_s_sel = ' '.join(output_s_sel.split()[1:])\n",
    "    \n",
    "    for i_s, o_a, o_s in zip(input_s.split('.'), output_s_all.split('.'), output_s_sel.split('.')):\n",
    "        if len(i_s) > 4:\n",
    "            f_in_all.write(i_s + '\\n')\n",
    "            f_out_all.write(o_a + '\\n')\n",
    "\n",
    "            f_in_sel.write(i_s + '\\n')\n",
    "            f_out_sel.write(o_s + '\\n')\n",
    "            if '_tag' in i_s:\n",
    "                r += 1\n",
    "    \n",
    "f_in_all.close()\n",
    "f_out_all.close()\n",
    "f_in_sel.close()\n",
    "f_out_sel.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
