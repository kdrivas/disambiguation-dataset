{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT_VERBS = ['tratar', 'estabelecer', 'marcar', 'vir', 'colocar',\\\n",
    "           'fechar', 'dar', 'cair', 'encontrar', 'registrar',\\\n",
    "           'levar', 'receber', 'apresentar', 'passar', 'deixar',\\\n",
    "           'chegar', 'ficar', 'fazer', 'ter', 'ser']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(startpath):\n",
    "    selected_files = []\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        level = root\n",
    "        for f in files:\n",
    "            if 'dls/verb' in level and '.xml' in f and 'ontology' not in f:\n",
    "                selected_files.append(level + '/' + f)\n",
    "    return selected_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_files = list_files(Path.cwd() / 'data/CSTNews 6.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_file = {}\n",
    "id_synstes = []\n",
    "with open(Path.cwd() / 'data/wordnet/index.sense') as f:\n",
    "    for ix, line in enumerate(f.read().split('\\n')):\n",
    "        if len(line) > 1:\n",
    "            verbs_file[line.split()[0]] = line.split()[1]\n",
    "            id_synstes.append(line.split()[1])\n",
    "f.close()\n",
    "id_synstes = list(set(id_synstes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_sentences = []\n",
    "stem_sentences = []\n",
    "output_sentences = []\n",
    "output_selected_verb_sentences = []\n",
    "selected_arrays = []\n",
    "total_anns = 0\n",
    "for name_file in selected_files:\n",
    "    with open(name_file, 'r') as f:\n",
    "        xml = f.read().lower()\n",
    "        texts = re.findall(r'<texto(.*?)</texto>', xml, re.DOTALL)\n",
    "        \n",
    "        for text in texts:\n",
    "            sentences = re.findall(r'<p>(.*?)</p>', text, re.DOTALL)\n",
    "            for sentence in sentences:\n",
    "                tokens = re.findall(r'<token>(.*?)</token>', text, re.DOTALL)\n",
    "                temp_in = []\n",
    "                temp_out = []\n",
    "                temp_stem = []\n",
    "                temp_sel = []\n",
    "                temp = []\n",
    "                for token in tokens:\n",
    "                    word_value = re.findall(r'<valor>(.*?)</valor>', token, re.DOTALL)\n",
    "                    sense_value = re.findall(r'<synset selecionado=\"true\">(.*?)</synset>', token, re.DOTALL)\n",
    "                    stem_value = re.findall(r'<lema>(.*?)</lema>', token, re.DOTALL)\n",
    "                    \n",
    "                    temp_in.append(word_value[0])\n",
    "                    temp_stem.append(stem_value[0])\n",
    "                    if len(sense_value) > 0:\n",
    "                        temp.append(word_value[0] + '<' + (8 - len(sense_value[0])) * '0' + sense_value[0] + '>')\n",
    "                        if stem_value[0] in PT_VERBS:\n",
    "                            temp_sel.append((8 - len(sense_value[0])) * '0' + sense_value[0])\n",
    "                        temp_out.append((8 - len(sense_value[0])) * '0' + sense_value[0])\n",
    "                    else:\n",
    "                        temp.append(word_value[0])\n",
    "                        temp_sel.append(word_value[0])\n",
    "                        temp_out.append(word_value[0])\n",
    "                        \n",
    "                selected_arrays.append(' '.join(temp))\n",
    "                input_sentences.append(' '.join(temp_in))\n",
    "                output_sentences.append(' '.join(temp_out))\n",
    "                stem_sentences.append(' '.join(temp_stem))\n",
    "                output_selected_verb_sentences.append(' '.join(temp_sel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = list(zip(selected_arrays, stem_sentences, output_sentences))\n",
    "selected = list(set(selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 1145, 1145)"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected), len(selected_arrays), len(output_selected_verb_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ocurrencias : 1326 0\n"
     ]
    }
   ],
   "source": [
    "d_selected_words = {verb:0 for verb in PT_VERBS}\n",
    "total_anns = 0\n",
    "not_exist = []\n",
    "for ix, (line_w, line_s, line_o) in enumerate(selected):\n",
    "            for word_w, word_s, word_o in zip(line_w.split(), line_s.split(), line_o.split()): \n",
    "                if '<' in word_w and '>' in word_w:\n",
    "                    if re.sub(r'<(.*?)>', '', word_s) in PT_VERBS:\n",
    "                        d_selected_words[word_s] += 1\n",
    "                        total_anns += 1\n",
    "                    if word_o not in id_synstes:\n",
    "                        not_exist.append(word_o)\n",
    "print('ocurrencias :', total_anns, len(not_exist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apresentar': 39,\n",
       " 'cair': 24,\n",
       " 'chegar': 57,\n",
       " 'colocar': 20,\n",
       " 'dar': 55,\n",
       " 'deixar': 51,\n",
       " 'encontrar': 27,\n",
       " 'estabelecer': 12,\n",
       " 'fazer': 119,\n",
       " 'fechar': 21,\n",
       " 'ficar': 71,\n",
       " 'levar': 34,\n",
       " 'marcar': 17,\n",
       " 'passar': 47,\n",
       " 'receber': 37,\n",
       " 'registrar': 27,\n",
       " 'ser': 478,\n",
       " 'ter': 159,\n",
       " 'tratar': 11,\n",
       " 'vir': 20}"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_selected_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = list(zip(input_sentences, output_sentences, output_selected_verb_sentences))\n",
    "sentences = list(set(sentences))\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\ufeff o presidente luiz inácio lula da silva disse na manhã desta segunda-feira , no programa café com o presidente , que o brasil se transformará em um \" canteiro de obra \" . o governo federal prepara o anúncio de uma série de investimentos na malha de transportes . eles devem ser anunciados pelo presidente na próxima semana , após viagem pela américa central . os recursos para a malha de transportes fazem parte dos r $ 504 bilhões previstos no programa de aceleração do crescimento ( pac ) . lula ressaltou que algumas das obras a serem anunciadas já estão em andamento e outras devem começar de imediato . também está prevista a inclusão de obras que ainda necessitam de licenciamento . - o dado concreto é que nós vamos fazer deste país um verdadeiro canteiro de obra em se tratando de infra-estrutura - disse o presidente . ele não antecipou o volume de recursos nem onde serão aplicados . mas , segundo o presidente , as obras de infra-estrutura serão realizadas em rodovias , ferrovias , gasodutos e aeroportos . - tudo que tiver de infra-estrutura na área de transportes nós vamos anunciar também e começar a liberar o dinheiro para que as obras comecem a acontecer . lula destacou que a liberação de recursos para obras de saneamento básico e habitação previstos no programa de aceleração do crescimento ( pac ) obedecerá critérios exclusivamente técnicos . segundo o presidente , r $ 106 bilhões serão destinados ao setor de habitação e outros r $ 40 bilhões serão investidos em saneamento básico .',\n",
       " '\\ufeff o presidente luiz inácio lula da silva 01009240 na manhã desta segunda-feira , no programa café com o presidente , que o brasil se 00382635 em um \" canteiro de obra \" . o governo federal 01754271 o anúncio de uma série de investimentos na malha de transportes . eles devem ser 00965871 pelo presidente na próxima semana , após viagem pela américa central . os recursos para a malha de transportes 02604760 parte dos r $ 504 bilhões previstos no programa de aceleração do crescimento ( pac ) . lula 01014609 que algumas das obras a serem 00965871 já 00344643 em andamento e outras devem 00345761 de imediato . também está 00678282 a inclusão de obras que ainda 01188725 de licenciamento . - o dado concreto 02604760 que nós vamos 00120316 deste país um verdadeiro canteiro de obra em se tratando de infra-estrutura - 01009240 o presidente . ele não 00719734 o volume de recursos nem onde serão 01158872 . mas , segundo o presidente , as obras de infra-estrutura serão 01640855 em rodovias , ferrovias , gasodutos e aeroportos . - tudo que 02603699 de infra-estrutura na área de transportes nós vamos 00965871 também e 00345761 a 02294436 o dinheiro para que as obras 00345761 a 00339934 . lula 01014609 que a liberação de recursos para obras de saneamento básico e habitação previstos no programa de aceleração do crescimento ( pac ) 02542795 critérios exclusivamente técnicos . segundo o presidente , r $ 106 bilhões serão 01158872 ao setor de habitação e outros r $ 40 bilhões serão 02271137 em saneamento básico .',\n",
       " '\\ufeff o presidente luiz inácio lula da silva na manhã desta segunda-feira , no programa café com o presidente , que o brasil se em um \" canteiro de obra \" . o governo federal o anúncio de uma série de investimentos na malha de transportes . eles devem ser pelo presidente na próxima semana , após viagem pela américa central . os recursos para a malha de transportes 02604760 parte dos r $ 504 bilhões previstos no programa de aceleração do crescimento ( pac ) . lula que algumas das obras a serem já em andamento e outras devem de imediato . também está a inclusão de obras que ainda de licenciamento . - o dado concreto 02604760 que nós vamos 00120316 deste país um verdadeiro canteiro de obra em se tratando de infra-estrutura - o presidente . ele não o volume de recursos nem onde serão . mas , segundo o presidente , as obras de infra-estrutura serão em rodovias , ferrovias , gasodutos e aeroportos . - tudo que 02603699 de infra-estrutura na área de transportes nós vamos também e a o dinheiro para que as obras a . lula que a liberação de recursos para obras de saneamento básico e habitação previstos no programa de aceleração do crescimento ( pac ) critérios exclusivamente técnicos . segundo o presidente , r $ 106 bilhões serão ao setor de habitação e outros r $ 40 bilhões serão em saneamento básico .')"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_in_all = open(Path.cwd() / 'data/disambiguation/test/all_verbs_in.txt', 'w')\n",
    "f_out_all = open(Path.cwd() / 'data/disambiguation/test/all_verbs_out.txt', 'w') \n",
    "f_in_sel = open(Path.cwd() / 'data/disambiguation/test/verbs_selected_in.txt', 'w')\n",
    "f_out_sel = open(Path.cwd() / 'data/disambiguation/test/verbs_selected_out.txt', 'w')\n",
    "\n",
    "for input_s, output_s_all, output_s_sel in sentences:\n",
    "    #print(input_s)\n",
    "    input_s = ' '.join(input_s.split()[1:])\n",
    "    output_s_all = ' '.join(output_s_all.split()[1:])\n",
    "    output_s_sel = ' '.join(output_s_sel.split()[1:])\n",
    "    \n",
    "    f_in_all.write(input_s + '\\n')\n",
    "    f_out_all.write(output_s_all + '\\n')\n",
    "    \n",
    "    f_in_sel.write(input_s + '\\n')\n",
    "    f_out_sel.write(output_s_sel + '\\n')\n",
    "    \n",
    "f_in_all.close()\n",
    "f_out_all.close()\n",
    "f_in_sel.close()\n",
    "f_out_sel.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_i = open(Path.cwd() / 'data/disambiguation/test/verbs_selected_in.txt', 'r')\n",
    "f_o = open(Path.cwd() / 'data/disambiguation/test/verbs_selected_out.txt', 'r')\n",
    "f = open(Path.cwd() / 'data/disambiguation/test/verbs_selected.tsv', 'w')\n",
    "array_senses = []\n",
    "for l_i, l_o in zip(f_i.read().split('\\n'), f_o.read().split('\\n')):\n",
    "    temp = []\n",
    "    for t_i, t_o in zip(l_i.split('.'), l_o.split('.')):\n",
    "        t_i\n",
    "        f.write(t_i + '\\t' + t_o + '\\n')\n",
    "f.close()\n",
    "f_i.close()\n",
    "f_o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_i = open(Path.cwd() / 'data/disambiguation/test/all_verbs_in.txt', 'r')\n",
    "f_o = open(Path.cwd() / 'data/disambiguation/test/all_verbs_out.txt', 'r')\n",
    "f = open(Path.cwd() / 'data/disambiguation/test/all_verbs.tsv', 'w')\n",
    "for l_i, l_o in zip(f_i.read().split('\\n'), f_o.read().split('\\n')):\n",
    "    for t_i, t_o in zip(l_i.split('.'), l_o.split('.')):\n",
    "        f.write(t_i + '\\t' + t_o + '\\n')\n",
    "f.close()\n",
    "f_i.close()\n",
    "f_o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
