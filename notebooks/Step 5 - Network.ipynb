{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "\n",
    "os.chdir('../')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.encoder import Encoder\n",
    "from model.decoder_v2 import Decoder_luong\n",
    "\n",
    "from src.utils import time_since\n",
    "from src.data import prepare_data\n",
    "from src.data_loader import get_loader\n",
    "from src.evaluator import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True\n",
    "MAX_LENGTH = 100\n",
    "DIR_FILES = 'data/disambiguation/'\n",
    "DIR_TRAIN = os.path.join(DIR_FILES, 'all')\n",
    "DIR_TEST = os.path.join(DIR_FILES, 'test')\n",
    "DIR_RESULTS = 'results/'\n",
    "SPLIT_TRAIN = 0.7\n",
    "SPLIT_VALID = 0.15\n",
    "# The rest is for test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 66620 train pairs\n",
      "Reading lines...\n",
      "Read 140 test pairs\n",
      "Filtered to 66380 pairs\n",
      "Creating vocab...\n",
      "Indexed 69224 words in input language, 83423 words in output\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs_train, pairs_test= prepare_data('all_rouge_map', 'verbs_selected', max_length=MAX_LENGTH, dir_train=DIR_TRAIN, dir_test=DIR_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_train = np.array(pairs_train)\n",
    "pairs_test = np.array(pairs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_batches, target_batches, \\\n",
    "          encoder, decoder, encoder_optimizer, decoder_optimzier, \\\n",
    "          criterion, max_length=MAX_LENGTH, train=True):\n",
    "    \n",
    "    if train:\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "    loss = 0\n",
    "    \n",
    "    batch_size = input_batches.size()[1]\n",
    "    \n",
    "    encoder_hidden = encoder.init_hidden(batch_size)\n",
    "    encoder_outputs, encoder_hidden = encoder(input_batches, encoder_hidden)\n",
    "    \n",
    "    decoder_context = Variable(torch.zeros(batch_size, decoder.hidden_size))   \n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    # set the start of the sentences of the batch\n",
    "    decoder_input = Variable(torch.LongTensor([input_lang.vocab.stoi['<sos>']] * batch_size))\n",
    "\n",
    "    # store the decoder outputs to estimate the loss\n",
    "    all_decoder_outputs = Variable(torch.zeros(target_batches.size()[0], batch_size, len(output_lang.vocab.stoi)))\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "        decoder_context = decoder_context.cuda()  \n",
    "    \n",
    "    if train:\n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    else:\n",
    "        use_teacher_forcing = False\n",
    "\n",
    "    if use_teacher_forcing:        \n",
    "        # Use targets as inputs\n",
    "        for di in range(target_batches.shape[0]):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input.unsqueeze(0), decoder_context, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            all_decoder_outputs[di] = decoder_output\n",
    "            decoder_input = target_batches[di]\n",
    "    else:        \n",
    "        # Use decoder output as inputs\n",
    "        for di in range(target_batches.shape[0]):            \n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input.unsqueeze(0), decoder_context, decoder_hidden, encoder_outputs) \n",
    "\n",
    "            all_decoder_outputs[di] = decoder_output\n",
    "            \n",
    "            # Greedy approach, take the word with highest probability\n",
    "            topv, topi = decoder_output.data.topk(1)            \n",
    "            decoder_input = Variable(torch.LongTensor(topi.cpu()).squeeze())\n",
    "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    loss = nn.NLLLoss()(all_decoder_outputs.view(-1, decoder.output_size), target_batches.contiguous().view(-1))          \n",
    "    \n",
    "    if train:\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "        torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1.post2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_model = 'general'\n",
    "hidden_size = 256\n",
    "emb_size = 300\n",
    "n_layers = 2\n",
    "seed = 12\n",
    "dropout_p = 0.2\n",
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "\n",
    "n_epochs = 40\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(len(input_lang.vocab.stoi), hidden_size, emb_size, n_layers, dropout_p, USE_CUDA=USE_CUDA)\n",
    "decoder = Decoder_luong(attn_model, hidden_size, len(output_lang.vocab.stoi), emb_size, 2 * n_layers, dropout_p, USE_CUDA=USE_CUDA)\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "    \n",
    "learning_rate = 0.001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters())\n",
    "decoder_optimizer = optim.Adam(decoder.parameters())\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "validation_acc = []\n",
    "\n",
    "plot_every = 5\n",
    "start_eval = 15\n",
    "print_every = 5\n",
    "validate_loss_every = 25\n",
    "best_acc = 0\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_loader(pairs_train, input_lang.vocab.stoi, output_lang.vocab.stoi, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 19s (- 12m 47s) (1 5%) 8.9294\n",
      "0m 36s (- 24m 2s) (1 10%) 4.5356\n",
      "0m 52s (- 34m 12s) (1 15%) 3.7169\n",
      "1m 9s (- 44m 55s) (1 20%) 3.4474\n",
      "1m 26s (- 56m 21s) (1 25%) 3.3652\n",
      "1m 42s (- 66m 49s) (1 30%) 3.2042\n",
      "1m 59s (- 77m 43s) (1 35%) 2.9129\n",
      "2m 18s (- 89m 45s) (1 40%) 3.0333\n",
      "2m 33s (- 99m 51s) (1 45%) 3.2498\n",
      "2m 51s (- 111m 19s) (1 50%) 2.7783\n",
      "3m 7s (- 121m 38s) (1 55%) 2.9454\n",
      "3m 24s (- 132m 37s) (1 60%) 3.1151\n",
      "3m 39s (- 142m 50s) (1 65%) 3.1249\n",
      "3m 56s (- 153m 26s) (1 70%) 3.2791\n",
      "4m 15s (- 165m 47s) (1 75%) 2.7932\n",
      "4m 29s (- 175m 11s) (1 80%) 3.1662\n",
      "4m 44s (- 185m 5s) (1 85%) 3.1078\n",
      "5m 0s (- 195m 14s) (1 90%) 3.1366\n",
      "5m 15s (- 205m 2s) (1 95%) 3.0716\n",
      "5m 31s (- 215m 11s) (1 100%) 3.0004\n",
      "5m 49s (- 227m 16s) (1 105%) 2.8469\n",
      "6m 5s (- 237m 23s) (1 110%) 2.9899\n",
      "6m 22s (- 248m 43s) (1 115%) 2.8820\n",
      "6m 37s (- 258m 39s) (1 120%) 3.1196\n",
      "6m 52s (- 268m 4s) (1 125%) 3.0404\n",
      "7m 9s (- 278m 55s) (1 130%) 2.9314\n",
      "7m 26s (- 290m 5s) (1 135%) 2.6563\n",
      "7m 43s (- 301m 16s) (1 140%) 2.8155\n",
      "8m 0s (- 312m 8s) (1 145%) 2.8878\n",
      "8m 16s (- 322m 25s) (1 150%) 2.8295\n",
      "8m 35s (- 335m 15s) (1 155%) 2.3922\n",
      "8m 53s (- 346m 45s) (1 160%) 2.8541\n",
      "9m 8s (- 356m 24s) (1 165%) 3.4041\n",
      "9m 24s (- 367m 3s) (1 170%) 2.9337\n",
      "9m 39s (- 376m 47s) (1 175%) 2.9996\n",
      "9m 59s (- 389m 29s) (1 180%) 2.7141\n",
      "10m 17s (- 401m 33s) (1 185%) 2.9914\n",
      "10m 34s (- 412m 38s) (1 190%) 2.9224\n",
      "10m 52s (- 424m 3s) (1 195%) 2.7684\n",
      "11m 10s (- 435m 56s) (1 200%) 2.6939\n",
      "11m 28s (- 447m 16s) (1 205%) 2.5844\n",
      "11m 43s (- 457m 29s) (1 210%) 2.8329\n",
      "12m 3s (- 470m 3s) (1 215%) 2.6564\n",
      "12m 18s (- 480m 14s) (1 220%) 2.9451\n",
      "12m 36s (- 491m 48s) (1 225%) 2.6064\n",
      "12m 53s (- 502m 55s) (1 230%) 2.7416\n",
      "13m 11s (- 514m 47s) (1 235%) 2.8750\n",
      "13m 30s (- 526m 33s) (1 240%) 2.7371\n",
      "13m 43s (- 535m 27s) (1 245%) 2.8868\n",
      "14m 3s (- 548m 10s) (1 250%) 2.5835\n",
      "14m 20s (- 559m 9s) (1 255%) 2.6471\n",
      "14m 36s (- 569m 26s) (1 260%) 2.7056\n",
      "14m 53s (- 580m 41s) (1 265%) 2.7945\n",
      "15m 10s (- 591m 56s) (1 270%) 2.6735\n",
      "15m 25s (- 601m 34s) (1 275%) 2.9800\n",
      "15m 40s (- 611m 32s) (1 280%) 3.0031\n",
      "15m 57s (- 622m 36s) (1 285%) 2.7210\n",
      "16m 14s (- 633m 33s) (1 290%) 2.7336\n",
      "16m 31s (- 644m 25s) (1 295%) 2.7000\n",
      "16m 50s (- 656m 31s) (1 300%) 2.6268\n",
      "17m 7s (- 667m 41s) (1 305%) 2.5920\n",
      "17m 23s (- 678m 35s) (1 310%) 2.8533\n",
      "17m 39s (- 688m 33s) (1 315%) 2.8222\n",
      "17m 54s (- 698m 9s) (1 320%) 2.9089\n",
      "18m 10s (- 708m 44s) (1 325%) 2.6312\n",
      "18m 25s (- 718m 25s) (1 330%) 2.6744\n",
      "18m 40s (- 728m 17s) (1 335%) 2.7817\n",
      "18m 56s (- 738m 30s) (1 340%) 2.7727\n",
      "19m 13s (- 749m 56s) (1 345%) 2.4276\n",
      "19m 28s (- 759m 48s) (1 350%) 2.7172\n",
      "19m 45s (- 770m 20s) (1 355%) 2.5766\n",
      "19m 58s (- 779m 6s) (1 360%) 2.6847\n",
      "20m 14s (- 789m 15s) (1 365%) 2.6812\n",
      "20m 33s (- 801m 36s) (1 370%) 2.3360\n",
      "20m 48s (- 811m 42s) (1 375%) 2.4396\n",
      "21m 5s (- 822m 26s) (1 380%) 2.4605\n",
      "21m 23s (- 834m 23s) (1 385%) 2.2692\n",
      "21m 40s (- 845m 13s) (1 390%) 2.5161\n",
      "21m 58s (- 857m 9s) (1 395%) 2.4055\n",
      "22m 15s (- 868m 1s) (1 400%) 2.4660\n",
      "22m 33s (- 879m 56s) (1 405%) 2.3481\n",
      "22m 50s (- 890m 44s) (1 410%) 2.4505\n",
      "23m 6s (- 901m 0s) (1 415%) 2.6771\n",
      "23m 22s (- 911m 33s) (1 420%) 2.5461\n",
      "23m 36s (- 920m 32s) (1 425%) 2.5445\n",
      "23m 50s (- 929m 37s) (1 430%) 2.7602\n",
      "24m 7s (- 940m 36s) (1 435%) 2.2895\n",
      "24m 23s (- 951m 18s) (1 440%) 2.4710\n",
      "24m 38s (- 960m 46s) (1 445%) 2.6848\n",
      "24m 55s (- 971m 49s) (1 450%) 2.5401\n",
      "25m 9s (- 981m 16s) (1 455%) 2.5668\n",
      "25m 27s (- 993m 5s) (1 460%) 2.3526\n",
      "25m 44s (- 1003m 44s) (1 465%) 2.2355\n",
      "25m 58s (- 1013m 6s) (1 470%) 2.2921\n",
      "26m 15s (- 1024m 6s) (1 475%) 2.2687\n",
      "26m 32s (- 1035m 12s) (1 480%) 2.2066\n",
      "26m 51s (- 1047m 12s) (1 485%) 2.0428\n",
      "27m 7s (- 1058m 8s) (1 490%) 2.1670\n",
      "27m 25s (- 1069m 28s) (1 495%) 2.3470\n",
      "27m 45s (- 1082m 21s) (1 500%) 2.2262\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs): \n",
    "    # Shuffle data\n",
    "    id_aux = np.random.permutation(np.arange(len(pairs_train)))\n",
    "    pairs_train = pairs_train[id_aux]\n",
    "    \n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    print_loss_total = 0\n",
    "    # Get the batches for this epoch\n",
    "    \n",
    "    for batch_ix, (input_var, _, target_var, _) in enumerate(train_loader):\n",
    "        # Transfer to GPU\n",
    "        input_var, target_var = input_var.to(device), target_var.to(device)\n",
    "\n",
    "        # Run the train function\n",
    "        loss = train(input_var, target_var,\\\n",
    "                 encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, \n",
    "                 max_length=MAX_LENGTH, train=True)\n",
    "        #loss = train_luong(input_var, target_var, input_var.size(1), True)\n",
    "            \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Keep track of loss\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if batch_ix == 0: continue\n",
    "\n",
    "        if batch_ix % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print_summary = '%s (%d %d%%) %.4f' % (time_since(start, epoch / n_epochs), epoch, batch_ix, print_loss_avg)\n",
    "            train_losses.append(loss)\n",
    "            print(print_summary)\n",
    "    \n",
    "    #input_batches, target_batches = generate_batches(input_lang, output_lang, batch_size, pairs_test, USE_CUDA=USE_CUDA)\n",
    "    #print_loss_total = 0\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    #for input_batch, target_var in zip(input_batches, target_batches):\n",
    "    \n",
    "    #    encoder.eval()\n",
    "    #    decoder.eval()\n",
    "    \n",
    "    #    #[input_var, _, _, _, _, _, _, _] = input_batch\n",
    "    #    input_var = input_batch\n",
    "    #    # Run the train function\n",
    "    #    loss = train(input_var, target_var,\\\n",
    "    #             encoder, decoder, encoder_optimizer, decoder_optimizer, criterion,\\\n",
    "    #             max_length=MAX_LENGTH, train=False)\n",
    "        \n",
    "    #    print_loss_total += loss\n",
    "    #val_loss = print_loss_total / len(input_batches)\n",
    "    #validation_losses.append(val_loss)\n",
    "    # Evaluating acc\n",
    "    if epoch > start_eval:\n",
    "        evaluator = Evaluator(encoder, decoder, input_lang, output_lang, MAX_LENGTH, True)\n",
    "        acc = evaluator.evaluate_acc(pairs_test, k_beams=1)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            torch.save(encoder.state_dict(), f'{DIR_RESULTS}/encoder.pkl')\n",
    "            torch.save(decoder.state_dict(), f'{DIR_RESULTS}/decoder.pkl')\n",
    "            print('Saving weights')\n",
    "        validation_acc.append(acc)\n",
    "        print(f'------------- acc: {acc}')\n",
    "\n",
    "        # Prevent overflow gpu memory\n",
    "        del evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03444953023367863"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del encoder\n",
    "del decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "encoder = Encoder(len(input_lang.vocab.stoi), hidden_size, emb_size, n_layers, dropout_p, USE_CUDA=USE_CUDA)\n",
    "decoder = Decoder_luong(attn_model, hidden_size, len(output_lang.vocab.stoi), emb_size, 2 * n_layers, dropout_p, USE_CUDA=USE_CUDA)\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "    \n",
    "encoder.load_state_dict(torch.load(f'{DIR_RESULTS}/encoder.pkl'))\n",
    "decoder.load_state_dict(torch.load(f'{DIR_RESULTS}/decoder.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder_luong(\n",
       "  (embedding): Embedding(23810, 300)\n",
       "  (rnn): GRU(300, 512, num_layers=4, dropout=0.2)\n",
       "  (attn): Attention(\n",
       "    (linear_out): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (out): Linear(in_features=512, out_features=23810, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krivas/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(encoder, decoder, input_lang, output_lang, MAX_LENGTH, True)\n",
    "acc = evaluator.evaluate_acc(pairs_test, k_beams=3, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3640086726090099"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37099494097807756"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
