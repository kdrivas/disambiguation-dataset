{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trnsl.1.1.20190208T160544Z.4984aee4447d8d41.9ded34b703cb87362a2a60d529d521163be1c8ae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://translate.yandex.net/api/v1.5/tr/translate\n",
    " ? key=<API key>\n",
    " & text=<text to translate>\n",
    " & lang=<translation direction>\n",
    " & [format=<text format>]\n",
    " & [options=<translation options>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element 'Translation' at 0x7f55d584b098> <?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<Translation code=\"200\" lang=\"en-pt\"><text>ele é um ser humano</text><align>0:13-0:19,0:2-0:3,3:2-4:1,6:7-6:13</align></Translation>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "r = requests.get(\"https://translate.yandex.net/api/v1.5/tr/translate\", \n",
    "                  data={'key': 'trnsl.1.1.20190208T160544Z.4984aee4447d8d41.9ded34b703cb87362a2a60d529d521163be1c8ae',\\\n",
    "                        'text': 'he is a human',\\\n",
    "                        'lang': 'en-pt',\\\n",
    "                        'options': '4'})\n",
    "\n",
    "temp = ElementTree.fromstring(r.text)\n",
    "print(ElementTree.fromstring(r.text), r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ele é um ser humano'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path.cwd()\n",
    "TRAIN_PATH = BASE_PATH / 'data/WSD_Evaluation_Framework/Training_Corpora/SemCor+OMSTI/semcor+omsti.data.xml'\n",
    "REMOVED_WORDS = ['&', '\\n']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_word(word):\n",
    "    for special_word in REMOVED_WORDS:\n",
    "        if special_word in word:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_senses(path):\n",
    "    map_wordnet = {}\n",
    "    t = []\n",
    "    with open(path) as file:\n",
    "        for line in file.read().split('\\n'):\n",
    "            if line == '':\n",
    "                continue\n",
    "            terms = line.split()\n",
    "            map_wordnet[terms[0]] = terms[1:]\n",
    "            \n",
    "    return map_wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_sentence_id(sentence):\n",
    "    tokens = []\n",
    "    token_id = 0\n",
    "    for temp in sentence:\n",
    "        if clean_word(temp):\n",
    "            for word in temp.split():\n",
    "                tokens.append(token_id)\n",
    "            token_id += 1\n",
    "            \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tagged_sentence(sentence, tags_sense, map_wordnet):\n",
    "    final_sentence = []\n",
    "    for ix, tag in enumerate(tags_sense):\n",
    "        temp = []\n",
    "        #print(sentence[ix])\n",
    "        if clean_word(sentence[ix]):\n",
    "            if tag != 'no_instance':\n",
    "                senses = map_wordnet[tag]\n",
    "                if len(senses) == 1:\n",
    "                    temp = senses[0]\n",
    "                else:\n",
    "                    # Replace this code\n",
    "                    temp = senses[0]\n",
    "            else:\n",
    "                temp = sentence[ix]\n",
    "            final_sentence.append(temp)\n",
    "        \n",
    "    return ' '.join(final_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_PATH) as f:\n",
    "    xml = f.read()\n",
    "    map_wordnet = load_senses(BASE_PATH / 'data/WSD_Evaluation_Framework/Training_Corpora/SemCor+OMSTI/semcor+omsti.gold.key.txt')\n",
    "    \n",
    "    context = re.findall(r'<sentence(.*?)</sentence>', xml, re.DOTALL)\n",
    "    word_ambiguos = re.findall(r'<head>(.*?)</head>', context[0], re.DOTALL)\n",
    "\n",
    "    sentences = re.split(r'[\\.|:|?|!]', context[0])\n",
    "    \n",
    "    list_instance = re.findall(r'<sentence(.*?)</sentence>', xml, re.DOTALL)\n",
    "    input_sentences = []\n",
    "    target_sentences = []\n",
    "    sentences_to_id = []\n",
    "\n",
    "    for ix, instance in enumerate(list_instance):\n",
    "        # Constructing train sentences\n",
    "        #print(ix)\n",
    "        \n",
    "        sentence = re.findall(r'>(.*?)<', instance, re.DOTALL)\n",
    "        input_sentences.append(' '.join([word for word in sentence if clean_word(word)]))     \n",
    "        sentences_to_id.append(convert_to_sentence_id(sentence))\n",
    "        \n",
    "        # Extracting tags wf or instance\n",
    "        labels = re.findall(r'</(.*?)>', instance, re.DOTALL)\n",
    "\n",
    "        # Mapping senses ids\n",
    "        tags_sense = re.findall(r'instance id=\"(.*?)\"', instance, re.DOTALL)\n",
    "        tags_sense.reverse()\n",
    "        tags_sense = [tags_sense.pop() if label == 'instance' else 'no_instance' for index, label in enumerate(labels)]\n",
    "\n",
    "        # Constructing test sentences\n",
    "        #target_sentences.append(get_tagged_sentence(sentence, tags_sense, map_wordnet))\n",
    "        target_sentences.append(tags_sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_requests = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/765452 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/765452 [00:01<295:35:05,  1.39s/it]\u001b[A\n",
      "  0%|          | 2/765452 [00:02<281:38:19,  1.32s/it]\u001b[A\n",
      "  0%|          | 3/765452 [00:03<274:00:20,  1.29s/it]\u001b[A\n",
      "  0%|          | 4/765452 [00:05<285:26:31,  1.34s/it]\u001b[A\n",
      "  0%|          | 5/765452 [00:06<287:45:54,  1.35s/it]\u001b[A\n",
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/krivas/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/krivas/anaconda3/lib/python3.6/site-packages/tqdm-4.19.5-py3.6.egg/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/krivas/anaconda3/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "  0%|          | 235/765452 [04:45<258:06:18,  1.21s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "for sentence in tqdm(input_sentences[85522:]):\n",
    "    r = requests.get(\"https://translate.yandex.net/api/v1.5/tr/translate\", \n",
    "                      data={'key': 'trnsl.1.1.20190208T160544Z.4984aee4447d8d41.9ded34b703cb87362a2a60d529d521163be1c8ae',\\\n",
    "                            'text': f'{sentence}',\\\n",
    "                            'lang': 'en-pt',\\\n",
    "                            'options': '4'})\n",
    "    api_requests.append(r)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "850974"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85522"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(api_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18, 17)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "ix = random.randint(0,9000)\n",
    "print(ix)\n",
    "len(input_sentences[ix].split()), len(target_sentences[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14, 13)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "ix = random.randint(0,9000)\n",
    "print(ix)\n",
    "len(input_sentences[ix].split()), len(target_sentences[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(58, 55)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "ix = random.randint(0,9000)\n",
    "print(ix)\n",
    "len(input_sentences[ix].split()), len(target_sentences[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no_instance',\n",
       " 'd023.s038.t000',\n",
       " 'no_instance',\n",
       " 'd023.s038.t001',\n",
       " 'no_instance',\n",
       " 'd023.s038.t002',\n",
       " 'no_instance',\n",
       " 'd023.s038.t003',\n",
       " 'no_instance',\n",
       " 'd023.s038.t004',\n",
       " 'no_instance',\n",
       " 'no_instance',\n",
       " 'no_instance']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_sentences[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He',\n",
       " 'opened',\n",
       " 'the',\n",
       " 'door',\n",
       " 'and',\n",
       " 'went',\n",
       " 'in',\n",
       " ',',\n",
       " 'pulling',\n",
       " 'it',\n",
       " 'shut',\n",
       " 'behind',\n",
       " 'him',\n",
       " '.']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentences[ix].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 27)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wf',\n",
       " 'wf',\n",
       " 'instance',\n",
       " 'wf',\n",
       " 'wf',\n",
       " 'instance',\n",
       " 'wf',\n",
       " 'instance',\n",
       " 'instance',\n",
       " 'instance',\n",
       " 'wf',\n",
       " 'wf',\n",
       " 'wf',\n",
       " 'instance',\n",
       " 'wf',\n",
       " 'instance',\n",
       " 'wf',\n",
       " 'instance',\n",
       " 'instance',\n",
       " 'instance',\n",
       " 'wf',\n",
       " 'wf',\n",
       " 'instance',\n",
       " 'wf',\n",
       " 'instance',\n",
       " 'instance',\n",
       " 'wf']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' id=\"d000.s002\">\\n<wf lemma=\"what\" pos=\"DET\">What</wf>\\n<instance id=\"d000.s002.t000\" lemma=\"effort\" pos=\"NOUN\">effort</instance>\\n<wf lemma=\"do\" pos=\"VERB\">do</wf>\\n<wf lemma=\"you\" pos=\"PRON\">you</wf>\\n<instance id=\"d000.s002.t001\" lemma=\"make\" pos=\"VERB\">make</instance>\\n<wf lemma=\"to\" pos=\"PRT\">to</wf>\\n<instance id=\"d000.s002.t002\" lemma=\"assess\" pos=\"VERB\">assess</instance>\\n<instance id=\"d000.s002.t003\" lemma=\"result\" pos=\"NOUN\">results</instance>\\n<wf lemma=\"of\" pos=\"ADP\">of</wf>\\n<wf lemma=\"you\" pos=\"PRON\">your</wf>\\n<instance id=\"d000.s002.t004\" lemma=\"program\" pos=\"NOUN\">program</instance>\\n<wf lemma=\"?\" pos=\".\">?</wf>\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " 'd000.s000.t000',\n",
       " None,\n",
       " None,\n",
       " 'd000.s000.t001',\n",
       " None,\n",
       " None,\n",
       " 'd000.s000.t002',\n",
       " None,\n",
       " 'd000.s000.t003',\n",
       " None,\n",
       " None,\n",
       " 'd000.s000.t004',\n",
       " None,\n",
       " 'd000.s000.t005',\n",
       " 'd000.s000.t006',\n",
       " None]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wf',\n",
       " 'instance',\n",
       " 'wf',\n",
       " 'wf',\n",
       " 'instance',\n",
       " 'wf',\n",
       " 'wf',\n",
       " 'instance',\n",
       " 'wf',\n",
       " 'instance',\n",
       " 'wf',\n",
       " 'wf',\n",
       " 'instance',\n",
       " 'wf',\n",
       " 'instance',\n",
       " 'instance',\n",
       " 'wf']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d000.s000.t006'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_sense.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_sense.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d000.s000.t005',\n",
       " 'd000.s000.t004',\n",
       " 'd000.s000.t003',\n",
       " 'd000.s000.t002',\n",
       " 'd000.s000.t001',\n",
       " 'd000.s000.t000']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What',\n",
       " 'effort',\n",
       " 'do',\n",
       " 'you',\n",
       " 'make',\n",
       " 'to',\n",
       " 'assess',\n",
       " 'results',\n",
       " 'of',\n",
       " 'your',\n",
       " 'program',\n",
       " '?']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 17)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence), len(tags_sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
